# ------------------------------------------------------------------
#  Modern-NCA on LimeSoDa
# ------------------------------------------------------------------
model: modernnca.ModernNCARegressor
random_state: 42
results_dir: results/limesoda_modernnca_optimize

# ----------------------- fixed parameters -------------------------
fixed_parameters:
  epochs: 256
  use_early_stopping: true           # enable patience–based early stop
  early_stopping_rounds: 16
  device: cuda                       # change to "cpu" if no GPU
  random_state: 42
  d_num: 0                           # treat all columns as “raw” features
  sample_rate: 0.8                   # % of retrieval memory to sample
  feature_scaling: robust
  standardize_targets: true

  

# --------------------- hyper-parameter search ---------------------
hyperparameter_grid:
  learning_rate:                     # Adam learning-rate
    type: float
    log: true
    low: 0.0001
    high: 0.01

  dim:                               # encoder output dimension
    type: int
    low: 64
    high: 256

  d_block:                           # width of blocks in post-encoder
    type: categorical
    choices: [128, 256, 512]

  n_blocks:                          # number of residual blocks
    type: int
    low: 0
    high: 3

  dropout:
    type: float
    low: 0.0
    high: 0.3

  temperature:                       # distance softmax temperature
    type: float
    log: true
    low: 0.1
    high: 5.0

  batch_size:
    type: categorical
    choices: [16, 32, 64]

# --------------------------- datasets ------------------------------
datasets:
  - dataset: B.204
    target: SOC_target
  - dataset: B.204
    target: pH_target
  - dataset: B.204
    target: Clay_target
  - dataset: BB.250
    target: SOC_target
  - dataset: BB.250
    target: pH_target
  - dataset: BB.250
    target: Clay_target
  - dataset: BB.51
    target: SOC_target
  - dataset: BB.51
    target: pH_target
  - dataset: BB.51
    target: Clay_target
  - dataset: BB.72
    target: SOC_target
  - dataset: BB.72
    target: pH_target
  - dataset: BB.72
    target: Clay_target
  - dataset: G.104
    target: SOC_target
  - dataset: G.104
    target: pH_target
  - dataset: G.104
    target: Clay_target
  - dataset: G.150
    target: SOC_target
  - dataset: G.150
    target: pH_target
  - dataset: G.150
    target: Clay_target
  - dataset: MG.112
    target: SOC_target
  - dataset: MG.112
    target: pH_target
  - dataset: MG.112
    target: Clay_target
  - dataset: MGS.101
    target: SOC_target
  - dataset: MGS.101
    target: pH_target
  - dataset: MGS.101
    target: Clay_target
  - dataset: NSW.52
    target: SOC_target
  - dataset: NSW.52
    target: pH_target
  - dataset: NSW.52
    target: Clay_target

# ----------------------- optimisation setup ------------------------
optimization:
  n_trials: 100
  sampler: TPE
  sampler_params:
    n_startup_trials: 20
  cv:
    outer_folds: 5
    inner_folds: 5

# ------------------ outer-fold training strategies -----------------
outer_train_strategies:
  agg_epochs_mean:
    enabled: true
  agg_epochs_mean_std:
    enabled: true
  agg_epochs_percentile:
    enabled: true
    percentile: 90
  best_inner_model:
    enabled: true
  full_train:
    enabled: true
    epochs: 256
  early_stopping:
    enabled: true
    val_frac: 0.2
  ensemble:
    enabled: true